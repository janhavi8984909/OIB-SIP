{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0756516",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# NYC Airbnb Data - Data Cleaning Notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook focuses on cleaning and preprocessing the NYC Airbnb dataset for analysis.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style for visualizations\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the raw data\\n\",\n",
    "    \"df = pd.read_csv('../data/raw/AB_NYC_2019.csv')\\n\",\n",
    "    \"print(\\\"Dataset loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"Original dataset shape: {df.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Initial Data Exploration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display basic information\\n\",\n",
    "    \"print(\\\"=== DATASET INFORMATION ===\\\")\\n\",\n",
    "    \"print(f\\\"Shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nColumns: {df.columns.tolist()}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nData Types:\\\")\\n\",\n",
    "    \"print(df.dtypes)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== FIRST 5 ROWS ===\\\")\\n\",\n",
    "    \"display(df.head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for missing values\\n\",\n",
    "    \"print(\\\"=== MISSING VALUES ===\\\")\\n\",\n",
    "    \"missing_data = df.isnull().sum()\\n\",\n",
    "    \"missing_percent = (missing_data / len(df)) * 100\\n\",\n",
    "    \"missing_df = pd.DataFrame({\\n\",\n",
    "    \"    'Missing Count': missing_data,\\n\",\n",
    "    \"    'Missing Percentage': missing_percent\\n\",\n",
    "    \"})\\n\",\n",
    "    \"display(missing_df[missing_df['Missing Count'] > 0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Basic statistics\\n\",\n",
    "    \"print(\\\"=== BASIC STATISTICS ===\\\")\\n\",\n",
    "    \"display(df.describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Cleaning Process\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a copy for cleaning\\n\",\n",
    "    \"df_clean = df.copy()\\n\",\n",
    "    \"print(\\\"Created working copy of the dataset\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.1 Handle Missing Values\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Handle missing values in 'reviews_per_month'\\n\",\n",
    "    \"print(\\\"Before handling 'reviews_per_month' missing values:\\\")\\n\",\n",
    "    \"print(f\\\"Missing values: {df_clean['reviews_per_month'].isnull().sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_clean['reviews_per_month'] = df_clean['reviews_per_month'].fillna(0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nAfter handling 'reviews_per_month' missing values:\\\")\\n\",\n",
    "    \"print(f\\\"Missing values: {df_clean['reviews_per_month'].isnull().sum()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Handle missing values in 'last_review'\\n\",\n",
    "    \"print(\\\"Before handling 'last_review' missing values:\\\")\\n\",\n",
    "    \"print(f\\\"Missing values: {df_clean['last_review'].isnull().sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_clean['last_review'] = df_clean['last_review'].fillna('No Review')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nAfter handling 'last_review' missing values:\\\")\\n\",\n",
    "    \"print(f\\\"Missing values: {df_clean['last_review'].isnull().sum()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.2 Check for Duplicates\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for duplicate rows\\n\",\n",
    "    \"duplicates = df_clean.duplicated().sum()\\n\",\n",
    "    \"print(f\\\"Number of duplicate rows: {duplicates}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if duplicates > 0:\\n\",\n",
    "    \"    df_clean = df_clean.drop_duplicates()\\n\",\n",
    "    \"    print(f\\\"Removed {duplicates} duplicate rows\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No duplicate rows found\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.3 Handle Outliers\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze price distribution before handling outliers\\n\",\n",
    "    \"print(\\\"=== PRICE DISTRIBUTION ANALYSIS ===\\\")\\n\",\n",
    "    \"print(f\\\"Price statistics before outlier handling:\\\")\\n\",\n",
    "    \"print(df_clean['price'].describe())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize price distribution\\n\",\n",
    "    \"plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.hist(df_clean['price'], bins=50, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"plt.title('Price Distribution (Original)')\\n\",\n",
    "    \"plt.xlabel('Price ($)')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.boxplot(df_clean['price'])\\n\",\n",
    "    \"plt.title('Price Boxplot (Original)')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Handle price outliers using IQR method\\n\",\n",
    "    \"Q1 = df_clean['price'].quantile(0.25)\\n\",\n",
    "    \"Q3 = df_clean['price'].quantile(0.75)\\n\",\n",
    "    \"IQR = Q3 - Q1\\n\",\n",
    "    \"lower_bound = Q1 - 1.5 * IQR\\n\",\n",
    "    \"upper_bound = Q3 + 1.5 * IQR\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Price IQR Analysis:\\\")\\n\",\n",
    "    \"print(f\\\"Q1 (25th percentile): {Q1:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Q3 (75th percentile): {Q3:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"IQR: {IQR:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Lower bound: {lower_bound:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Upper bound: {upper_bound:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Outliers before handling: {(df_clean['price'] > upper_bound).sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Cap outliers instead of removing them\\n\",\n",
    "    \"df_clean['price'] = np.where(df_clean['price'] > upper_bound, upper_bound, df_clean['price'])\\n\",\n",
    "    \"df_clean['price'] = np.where(df_clean['price'] < lower_bound, lower_bound, df_clean['price'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Outliers after handling: {(df_clean['price'] > upper_bound).sum()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize price distribution after outlier handling\\n\",\n",
    "    \"plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.hist(df_clean['price'], bins=50, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"plt.title('Price Distribution (After Outlier Handling)')\\n\",\n",
    "    \"plt.xlabel('Price ($)')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.boxplot(df_clean['price'])\\n\",\n",
    "    \"plt.title('Price Boxplot (After Outlier Handling)')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.4 Create New Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create price categories\\n\",\n",
    "    \"df_clean['price_category'] = pd.cut(df_clean['price'], \\n\",\n",
    "    \"                                 bins=[0, 100, 200, 500, float('inf')],\\n\",\n",
    "    \"                                 labels=['Budget', 'Moderate', 'Expensive', 'Luxury'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create availability status\\n\",\n",
    "    \"df_clean['availability_status'] = np.where(df_clean['availability_365'] > 180, 'High', 'Low')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create host experience categories\\n\",\n",
    "    \"df_clean['host_experience'] = pd.cut(df_clean['number_of_reviews'],\\n\",\n",
    "    \"                                  bins=[-1, 0, 10, 50, float('inf')],\\n\",\n",
    "    \"                                  labels=['New', 'Beginner', 'Experienced', 'Veteran'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create review status\\n\",\n",
    "    \"df_clean['has_reviews'] = df_clean['number_of_reviews'] > 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"New features created:\\\")\\n\",\n",
    "    \"print(\\\"- price_category: Budget, Moderate, Expensive, Luxury\\\")\\n\",\n",
    "    \"print(\\\"- availability_status: High, Low\\\")\\n\",\n",
    "    \"print(\\\"- host_experience: New, Beginner, Experienced, Veteran\\\")\\n\",\n",
    "    \"print(\\\"- has_reviews: True/False\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.5 Data Quality Checks\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Final data quality checks\\n\",\n",
    "    \"print(\\\"=== FINAL DATA QUALITY CHECK ===\\\")\\n\",\n",
    "    \"print(f\\\"Final dataset shape: {df_clean.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Missing values: {df_clean.isnull().sum().sum()}\\\")\\n\",\n",
    "    \"print(f\\\"Duplicate rows: {df_clean.duplicated().sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for negative values in numerical columns\\n\",\n",
    "    \"numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"print(\\\"\\\\nNegative values check:\\\")\\n\",\n",
    "    \"for col in numerical_cols:\\n\",\n",
    "    \"    negative_count = (df_clean[col] < 0).sum()\\n\",\n",
    "    \"    print(f\\\"{col}: {negative_count} negative values\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check data types\\n\",\n",
    "    \"print(\\\"\\\\nData types:\\\")\\n\",\n",
    "    \"print(df_clean.dtypes)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Save Cleaned Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save cleaned dataset\\n\",\n",
    "    \"df_clean.to_csv('../data/processed/cleaned_airbnb.csv', index=False)\\n\",\n",
    "    \"print(\\\"Cleaned dataset saved to '../data/processed/cleaned_airbnb.csv'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display final dataset info\\n\",\n",
    "    \"print(\\\"\\\\n=== CLEANING SUMMARY ===\\\")\\n\",\n",
    "    \"print(f\\\"Original dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Cleaned dataset shape: {df_clean.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Rows removed: {df.shape[0] - df_clean.shape[0]}\\\")\\n\",\n",
    "    \"print(f\\\"New features added: 4\\\")\\n\",\n",
    "    \"print(\\\"\\\\nCleaning process completed successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display sample of cleaned data\\n\",\n",
    "    \"print(\\\"=== SAMPLE OF CLEANED DATA ===\\\")\\n\",\n",
    "    \"display(df_clean.head(10))\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
